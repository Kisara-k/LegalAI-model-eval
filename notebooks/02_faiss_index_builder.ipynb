{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e140b48",
   "metadata": {},
   "source": [
    "# FAISS Index Builder (GPU)\n",
    "\n",
    "**⚠️ This notebook requires a GPU environment!**\n",
    "\n",
    "This notebook builds FAISS indices for all embedding models:\n",
    "1. Legal-BERT (`nlpaueb/legal-bert-base-uncased`)\n",
    "2. GTE-Large (`thenlper/gte-large`)\n",
    "3. BGE-Large (`BAAI/bge-large-en-v1.5`)\n",
    "\n",
    "For both:\n",
    "- Content field\n",
    "- Metadata field\n",
    "\n",
    "Indices are saved to disk for later use on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a541f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from src.data_loader import load_data, prepare_data, get_documents_by_field\n",
    "from src.faiss_retriever import FAISSRetriever, build_all_indices\n",
    "from src.config import EMBEDDING_MODELS, INDICES_DIR, EMBEDDING_BATCH_SIZE\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd04c4d6",
   "metadata": {},
   "source": [
    "## 1. Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec92d1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"\\n⚠️ WARNING: No GPU detected!\")\n",
    "    print(\"This notebook is designed for GPU. Index building will be slow on CPU.\")\n",
    "    print(\"Consider running on a GPU-enabled environment (Google Colab, Kaggle, etc.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fbed2e",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c0a0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = load_data()\n",
    "df = prepare_data(df)\n",
    "\n",
    "print(f\"Loaded {len(df)} documents\")\n",
    "\n",
    "# Get document lists\n",
    "documents_content = get_documents_by_field(df, 'content')\n",
    "documents_metadata = get_documents_by_field(df, 'metadata')\n",
    "\n",
    "print(f\"Content documents: {len(documents_content)}\")\n",
    "print(f\"Metadata documents: {len(documents_metadata)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deee64f5",
   "metadata": {},
   "source": [
    "## 3. Review Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42853ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display embedding models\n",
    "print(\"Embedding Models Configuration:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for key, config in EMBEDDING_MODELS.items():\n",
    "    print(f\"\\n{key}:\")\n",
    "    print(f\"  Model: {config['name']}\")\n",
    "    print(f\"  Description: {config['description']}\")\n",
    "    print(f\"  Max Length: {config['max_length']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1e2717",
   "metadata": {},
   "source": [
    "## 4. Build All FAISS Indices\n",
    "\n",
    "This will build 6 indices total:\n",
    "- 3 models × 2 fields (content + metadata)\n",
    "\n",
    "**Note:** This may take 30-60 minutes depending on GPU and dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ae0d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build all indices\n",
    "# Set use_gpu=True if GPU is available, False otherwise\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "print(f\"Building indices with GPU: {use_gpu}\")\n",
    "print(f\"Batch size: {EMBEDDING_BATCH_SIZE}\")\n",
    "print(f\"\\nThis will take some time...\\n\")\n",
    "\n",
    "build_all_indices(\n",
    "    documents_content=documents_content,\n",
    "    documents_metadata=documents_metadata,\n",
    "    use_gpu=use_gpu,\n",
    "    batch_size=EMBEDDING_BATCH_SIZE\n",
    ")\n",
    "\n",
    "print(\"\\n✓ All indices built and saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fd9866",
   "metadata": {},
   "source": [
    "## 5. Verify Saved Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aa5741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all saved indices\n",
    "import json\n",
    "\n",
    "print(\"Saved FAISS Indices:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for model_key in EMBEDDING_MODELS.keys():\n",
    "    for field in ['content', 'metadata']:\n",
    "        index_dir = INDICES_DIR / f\"{field}_{model_key}\"\n",
    "        \n",
    "        if index_dir.exists():\n",
    "            # Load metadata\n",
    "            metadata_file = index_dir / \"metadata.json\"\n",
    "            if metadata_file.exists():\n",
    "                with open(metadata_file, 'r') as f:\n",
    "                    metadata = json.load(f)\n",
    "                \n",
    "                print(f\"\\n{field}_{model_key}:\")\n",
    "                print(f\"  Model: {metadata['model_name']}\")\n",
    "                print(f\"  Documents: {metadata['num_documents']}\")\n",
    "                print(f\"  Dimension: {metadata['dimension']}\")\n",
    "                \n",
    "                # Check file sizes\n",
    "                index_file = index_dir / \"index.faiss\"\n",
    "                if index_file.exists():\n",
    "                    size_mb = index_file.stat().st_size / (1024 * 1024)\n",
    "                    print(f\"  Index size: {size_mb:.2f} MB\")\n",
    "        else:\n",
    "            print(f\"\\n⚠️ {field}_{model_key}: NOT FOUND\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3439ec3c",
   "metadata": {},
   "source": [
    "## 6. Test Index Loading (Quick Verification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea63309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading one index to verify it works\n",
    "test_model = \"legal-bert\"\n",
    "test_field = \"content\"\n",
    "\n",
    "print(f\"Testing index loading: {test_field}_{test_model}\")\n",
    "\n",
    "index_path = INDICES_DIR / f\"{test_field}_{test_model}\"\n",
    "retriever = FAISSRetriever(test_model, index_path=index_path)\n",
    "\n",
    "# Test retrieval\n",
    "test_query = \"What are the procedures for presidential elections?\"\n",
    "indices, scores, ret_time = retriever.retrieve(test_query, top_k=5)\n",
    "\n",
    "print(f\"\\nTest query: {test_query}\")\n",
    "print(f\"Retrieval time: {ret_time:.4f}s\")\n",
    "print(f\"\\nTop 5 results:\")\n",
    "for i, (idx, score) in enumerate(zip(indices, scores)):\n",
    "    print(f\"  {i+1}. Index: {idx}, Score: {score:.4f}\")\n",
    "\n",
    "print(\"\\n✓ Index loading and retrieval working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef07d2e4",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "FAISS index building complete!\n",
    "\n",
    "Created indices:\n",
    "1. **Legal-BERT** (content + metadata)\n",
    "   - Domain-specific legal model\n",
    "   - Best for legal terminology understanding\n",
    "\n",
    "2. **GTE-Large** (content + metadata)\n",
    "   - State-of-the-art general embedding\n",
    "   - Strong cross-domain performance\n",
    "\n",
    "3. **BGE-Large** (content + metadata)\n",
    "   - Top MTEB leaderboard model\n",
    "   - Excellent for retrieval tasks\n",
    "\n",
    "All indices saved to: `../indices/`\n",
    "\n",
    "Next steps:\n",
    "- Run retrieval evaluation on CPU (notebook 04)\n",
    "- Compare with BM25 results\n",
    "- Apply reranking (notebook 05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
